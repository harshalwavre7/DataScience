Micro codes for checking the Pandas


# Read CSV in chunks
data_read = pd.read_csv('Count_DOB.csv',chunksize=1000,encoding = "ISO-8859-1")      
data = pd.concat(data_read,ignore_index=True)    

# Split the dataframe based on the numeric and categorical values 

#	Numeric Split
cleansed_data_numeric = data.select_dtypes(include=['number']).columns
data_read_numeric = data.loc[:,lambda data : cleansed_data_numeric]
numeric_null_count = data_read_numeric.apply(lambda x : sum(x.notnull()))

# 	Categorical Split
cleansed_data_category = data.select_dtypes(exclude=['number']).columns
data_read_category = data.loc[:,lambda data : cleansed_data_category]
categorical_null_count = data_read_category.apply(lambda x : sum(x.notnull()))

# Date Difference and Date Conversion Logic
import datetime as DT
	data['DOB_NEW'].dtype
	#pd.to_datetime(data['DOB_NEW']) 
now = pd.Timestamp(DT.datetime.now())
data['DOB_NEW'] = pd.to_datetime(data['DOB_NEW'], format='%m/%d/%Y')    # 1

# Difference
data['DOB_NEW'] =data['DOB_NEW'].where(data['DOB_NEW'] < now, data['DOB_NEW'] -  np.timedelta64(100, 'Y'))   # 2
data['Age_Driver1'] = (now - data['DOB_NEW']).astype('<m8[Y]')    # 3

# Copying chunks of data from one frame to another 
# data=original frame ptsdriver2 = copied frame
ptsdriver2 = data[['ViolPoints2Driver_2',
'ViolPoints1Driver_2',
'ViolPoints3Driver_2',
'ViolPoints4Driver_2',
'ViolPoints5Driver_2',
'ViolPoints6Driver_2',
'ViolPoints7Driver_2',
'ViolPoints8Driver_2',
]].copy()
 
# Sum of values in the frame row-wise
ptsdriver2['Points_Driver2'] = ptsdriver2.apply(lambda x : x.sum(),axis=1)

# Replace Blank values with NaN 
dataframe.replace(r'^\s*$', np.NaN, regex=True, inplace = True)

# Scaling the values to remove if you want to treat numeric values on same scale 
# Libraries
from sklearn.preprocessing import StandardScaler
Step1 : Create Scale_clean using
Example : 
scale_clean = StandardScaler().fit(data[['Zip']])
Step2 :  Create Clean transform 
Example : 
clean_transform = scale_clean.transform(data[['Zip']])
Step3 : Create dataframe of the Clean Transform
Example : clean = pd.DataFrame(clean_transform)
Step4 : Join/Concatenate the Frames
frames = [data,clean]
data = pd.concat(frames,axis=1)
Step4 : Drop the Original Columns and Rename the New Ones 
data = data.drop(['Zip'],1)
data = data.rename(columns={0:'Zip'})
   

#Copying the data in a different frame based on column value condition

datax = data[data['Gender']=='M']

## Join two columns 
data['Policy'] = data[['policynum','policyseq']].apply(lambda x : '-'.join(x.astype(str)),axis=1)

#### Convert Multiple Columns into one 
##Using Ravel Flatten
x2 = pd.concat([titanic_train,pd.Series(titanic_train.values.ravel('F'))],axis=1)
## Also Melt
x1 = pd.melt(titanic_train)

df.sort_values('value')
tmp = df.groupby('group').size()
rank = tmp.map(range)
rank =[item for sublist in rank for item in sublist]
df['rank'] = rank


""" Box Plot """
""" Box basic plot is used to check the distribution / saturation of data """
""" Input Required x = Column name data = dataframe """
def box_basic_plot(x,data):
    import seaborn as sns
    plot = sns.boxplot(x=data[x],data=data)
    plot.set_title("Box Plot of "+" " + x, 
                 fontsize=18)    
    fig = plot.get_figure()
    fig.savefig(x+ "_Box_Plot"+".png")
box_basic_plot('PaidTotal',premium_non_zero)

""" Box Plot Group """
""" Box basic plot is used to check the distribution / saturation of data across group """
""" Input Required x = continuous column y = column used for grouping(category) name data = dataframe """
def box_group_plot(x,y,data):
    import seaborn as sns
    plot = sns.boxplot(x=data[x],y=data[y],data=data)
    plot.set_title("Box Plot "+" " + x +" "+"Vs"+" "+y, 
                 fontsize=18)    
    fig = plot.get_figure()
    fig.savefig(x+ "_Box_Group_Plot"+".png")
box_group_plot('ClaimStatus','PaidTotal',premium_non_zero)

""" Scatter Plot """
""" Check the relationship between two continuous variables in the data """
""" Input Required x = continous column y = continous column data = dataframe """
def scatter_basic_plot(x,y,data):
    import seaborn as sns
    plot = sns.regplot(x=data[x], y=data[y], fit_reg=False)
    plot.set_title("Scatter Plot of "+" " + x +" "+"Vs"+" "+y, 
                 fontsize=18)    
    fig = plot.get_figure()
    fig.savefig(x+ y + "_Scatter_Plot"+".png")
scatter_basic_plot('Violations_Points_Driver1_main','PaidTotal',premium_non_zero)    

""" Distribution Plot """
""" To check the overall distribution of data """
""" Input Required x = continuous variable data = dataframe """
def distribution_plot(x,data):
    import seaborn as sns
    plot = sns.distplot (data[x])
    plot.set_title("Distribution Plot of "+" "+x, 
                 fontsize=18)    
    fig = plot.get_figure()
    fig.savefig(x+"_Distribution_Plot"+".png")
distribution_plot('PaidTotal',premium_non_zero)    

""" Count Plot """
""" Check the count across groups without value on bar graphs with ungrouped column names"""
""" Input Required x = discrete category column y = column used for grouping(category) name data = dataframe """
def count_plot(x,y,data):
    import seaborn as sns
    plot = sns.countplot(x=data[x],hue=data[y],data=data)
    plot.set_title("Count Plot "+" " + x +" "+"Vs"+" "+y, 
                 fontsize=18)
    
    fig = plot.get_figure()
    fig.savefig(x+"_Count_Plot"+".png")
count_plot('CoverageLiability','ClaimStatus',premium_non_zero)

""" Count Plot """
""" Check the count across groups without value on bar graphs with grouped column name"""
""" Input Required x = discrete category column y = column used for grouping(category) name data = dataframe """
def count_group_plot(x,y,data):
#    test = data.groupby([x,y],sort=False).size().unstack()
    test = data.groupby([x,y],sort=False).size()
    ax = test.plot.bar(width=.8,legend=False,rot=0)
    ax.set_title("Count Plot "+" " + x +" "+"Vs"+" "+y, 
                 fontsize=18)
    
    for i, v in test.reset_index().iterrows():
#        print(i,v[0],v[1])
        plot = ax.text(i,v[0],v[0],
#                       i,v[1],v[1],
                       color='black')
        
    fig = plot.get_figure()
    fig.savefig(x+y+"_Count_Group_Plot"+".png")
count_group_plot('CoverageLiability','ClaimStatus',premium_non_zero)     

""" Count Plot """
""" Check the count across groups with value on bar graphs with ungrouped column name"""
""" Input Required x = discrete category column y = column used for grouping(category) name data = dataframe """
def count_group_new_plot(x,y,data):
    test = data.groupby([x,y],sort=False).size().unstack()
    test.rename(columns={
            0:test.columns[0],
            1:test.columns[1]
            },inplace=True)
    ax = test[[0,1]].plot(kind='bar',
                  figsize=(15,7), color=['dodgerblue', 'slategray'], rot=0,fontsize=13)
    ax.set_title("Count Plot "+" " + x +" "+"Vs"+" "+y, 
                 fontsize=18)
    #yu = premium_non_zero.groupby(['CoverageLiability','ClaimStatus'],sort=False).size().values
    #ax.set_yticks(yu.tolist())
    x_offset = -0.03
    y_offset = 0.02
    # set individual bar lables using above list
    for p in ax.patches:
        b = p.get_bbox()
        val = "{:.0f}".format(b.y1 + b.y0)        
        plot = ax.annotate(val, ((b.x0 + b.x1)/2 + x_offset, b.y1 + y_offset))
    fig = plot.get_figure()
    fig.savefig(x+y+"_Count_Group_Plot"+".png")
count_group_new_plot('CoverageLiability','ClaimStatus',premium_non_zero)     


#speed = [0.1, 17.5, 40, 48, 52, 69, 88]
#lifespan = [2, 8, 70, 1.5, 25, 12, 28]
#index = ['snail', 'pig', 'elephant',
#          'rabbit', 'giraffe', 'coyote', 'horse']
#df = pd.DataFrame({'speed': speed,
#                   'lifespan': lifespan}, index=index)
#test = premium_non_zero.groupby(['CoverageLiability','ClaimStatus'],sort=False).size().unstack()
#ax = test.plot.bar(rot=0)
#
#
#test = premium_non_zero.groupby(['CoverageLiability','ClaimStatus'],sort=False).size().to_frame()
#ax = test.plot.bar(width=.8,legend=False,rot=0)
#for i, v in test.reset_index().iterrows():
#    ax.text(i, v[0] + 0.2 , v[0], color='red')

import numpy as np
#df=pd.DataFrame({'A':np.random.rand(2)-1,'B':np.random.rand(2)},index=['val1','val2'] )
#ax = df.plot(kind='bar', color=['r','b']) 
#x_offset = -0.03
#y_offset = 0.02
#for p in ax.patches:
#    b = p.get_bbox()
#    val = "{:+.2f}".format(b.y1 + b.y0)        
#    ax.annotate(val, ((b.x0 + b.x1)/2 + x_offset, b.y1 + y_offset))
""" Correlation Plot """
""" Correaltion matrix of the Numerical variables in the given dataset """
""" Input Required df = dataframe """
def corr_plot(df,size=10):
    import seaborn as sns
#    age = data_claim[['Age1','Age2','Age3']]  Written to test the correlation plot 
#    corr = age.corr()
    corr = df.corr()
    import matplotlib.pyplot as plt
    # Generate a mask for the upper triangle
    mask = np.zeros_like(corr, dtype=np.bool)
    mask[np.triu_indices_from(mask)] = True
    
    # Set up the matplotlib figure
    f, ax = plt.subplots(figsize=(11, 9))
    
    # Generate a custom diverging colormap
    cmap = sns.diverging_palette(220, 10, as_cmap=True)
    
    # Draw the heatmap with the mask and correct aspect ratio
    plot = sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,
                square=True, linewidths=.5, cbar_kws={"shrink": .5})
    plot.set_title("Correlation Plot of Numeric Variables", 
                 fontsize=18)
    fig = plot.get_figure()
    fig.savefig("Correlation_Plot"+".png")
corr_plot(age)

""" Probability Plot """
""" Probability plot used to check the normality of data """
""" Input Required x = Column name data = dataframe """
def probability_plot(x,data):
    from scipy import stats
    import matplotlib.pyplot as plt
    fig = plt.figure()
    ax = fig.add_subplot(111)
    res = stats.probplot(data[x], plot=ax)
    ax.set_title("Probabilty plot for "+x) 
    fig = ax.get_figure()
    fig.savefig("Probability_Plot"+".png")
probability_plot('Age1',data_claim)

""" Logarithmic Probability Plot """
""" Probability plot used to check the normality of data on the log of the continuous variable """
""" Input Required x = Column name data = dataframe """
def log_probability_plot(x,data):
    from scipy import stats
    import matplotlib.pyplot as plt
    fig = plt.figure()
    ax = fig.add_subplot(111)
#    x = stats.loggamma.rvs(c=2.5)
    res = stats.probplot(data[x], dist=stats.loggamma, sparams=(2.5,), plot=ax)
#    res = stats.probplot(data_claim['Age1'], dist=stats.loggamma, sparams=(2.5,), plot=ax)
    ax.set_title("Probplot for loggamma dist with shape parameter 2.5 for "+ x)    
    fig = ax.get_figure()
    fig.savefig("Logarithmic _Probability_Plot"+".png")    
log_probability_plot('Age1',data_claim)

def pandas_classification_report(y_true, y_pred,model_name,type_col,sample_type):
    metrics_summary = precision_recall_fscore_support(
            y_true=y_true, 
            y_pred=y_pred)

    avg = list(precision_recall_fscore_support(
            y_true=y_true, 
            y_pred=y_pred,
            average='weighted'))
    
    y_test = y_true
    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']
    class_report_df = pd.DataFrame(
        list(metrics_summary),
        index=metrics_sum_index)
    class_report_df = class_report_df.round(2)
    support = class_report_df.loc['support']
    total = support.sum() 
    avg[-1] = total
    
    class_report_df['avg / total'] = avg
        
    class_report_df['Blank'] = ['','','','']
    
    
    class_report_df_T = class_report_df.T
    class_report_df_T['model_name'] = model_name
    class_report_df_T['Type_Col']=type_col
    class_report_df_T['Sampling_type']= sample_type
    
    class_report_df_T.index
    class_report_df_T = class_report_df_T.reset_index()
    class_report_df_T.loc[3] = ['','','','','','','','']
    cnf_mat = confusion_matrix(y_test,y_pred) 
    df_mat = pd.DataFrame(cnf_mat)
    class_report_df_T['0_predicted'] = df_mat[0]
    class_report_df_T['1_predicted'] = df_mat[1]
    score = accuracy_score(y_test,y_pred)
    class_report_df_T['Accuracy_Score']=[score*100,'','','']
#    for x in class_report_df_T.columns.tolist():
#    class_report_df_T = class_report_df_T.round(2)
    return class_report_df_T

Example

output=pandas_classification_report(y_test,y_pred,"LightGBM","31 cols","None")

results = results.append(output) 
