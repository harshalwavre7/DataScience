from pyspark.sql import functions as F

# Count vertices in each component
component_counts = components.groupBy("component").agg(F.count("*").alias("count"))

# Filter components where count >= 2
valid_components = component_counts.filter("count >= 2")

# Join back to get only valid subgraphs
subgraph_vertices = components.join(valid_components, "component").select("id")

# Filter edges where both src and dst are in the valid subgraph
subgraph_edges = g.edges.alias("e").join(subgraph_vertices.alias("v"), F.col("e.dst") == F.col("v.id"), "inner") \
                         .select("e.src", "e.dst")

# Create the subgraph
subgraph = GraphFrame(subgraph_vertices, subgraph_edges)

subgraph.vertices.show()
subgraph.edges.show()
